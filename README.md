# ğŸŒ‰ BridgeAI

**An Online-First AI Assistant with Automatic Offline Fallback**

BridgeAI is a **hybrid AI assistant** that prioritizes fast cloud AI (Cerebras) when internet is available, and seamlessly falls back to a local model when the connection drops - ensuring you **never lose access** to AI assistance.

*Built by Team Cyber_Samurais for WeMakeDevs FutureStack GenAI Hackathon '25*

---

## ğŸ¯ The Problem We Solve

Ever had an AI assistant fail because your internet dropped? **BridgeAI solves this.**

- **Traditional AI**: Breaks when internet fails âŒ
- **BridgeAI**: Automatically switches to local model âœ…

Perfect for:
- ğŸŒ Remote/rural areas with unreliable internet
- âœˆï¸ Working while traveling (airplane mode)
- ğŸ”’ Privacy-sensitive tasks (use offline mode)
- ï¿½ Cost-conscious users (reduce API costs)
- ğŸ¥ Critical applications (healthcare, emergency services)

---

## âœ¨ Key Features

- ğŸŒ **Online-First**: Fast cloud AI (Cerebras llama-3.3-70b) when connected
- ğŸ”„ **Automatic Fallback**: Seamlessly switches to local model when internet drops
- ğŸ¤– **Zero Manual Switching**: Detects network changes automatically
- ğŸ³ **Docker Containerized**: Professional deployment, one-command setup
- ğŸ¯ **MCP Gateway**: Smart routing layer using Model Context Protocol
- ï¿½ **Privacy Option**: Fully functional offline mode (data stays local)
- âš¡ **Always Responsive**: Never shows "No connection" errors

---

## ğŸš€ Quick Start

### For Hackathon Judges ğŸ†
ğŸ“– **[See FOR_JUDGES.md for complete testing guide](FOR_JUDGES.md)**

### Quick Setup (Windows)

1. **Install Prerequisites**
   - Docker Desktop: https://www.docker.com/products/docker-desktop/
   - Cerebras API Key (FREE): https://cloud.cerebras.ai/

2. **Run setup**
   ```bash
   setup.bat
   ```
   - Downloads AI model (~4GB, one-time)
   - Prompts for API key
   - Configures environment

3. **Start the app**
   ```bash
   start.bat
   ```
   - Builds Docker images (first run only, ~5-10 min)
   - Opens browser automatically

4. **Test the hybrid feature!**
   - Chat while online â†’ fast responses
   - Disconnect WiFi â†’ keeps working (offline mode)
   - Reconnect WiFi â†’ switches back automatically

ğŸ“– **[See QUICKSTART.md for detailed instructions](QUICKSTART.md)**

---

## ğŸ—ï¸ Architecture

```
User's Computer (Docker Container)
â”‚
â”œâ”€â”€ Frontend (React + Vite) :5173
â”œâ”€â”€ Backend (FastAPI) :8000
â”œâ”€â”€ MCP Gateway (Network Router) :8080
â””â”€â”€ Local Model (Llama 2 - 7B)

Network Detection:
â”œâ”€â”€ ONLINE  â†’ Routes to Cerebras API (fast, cloud-based)
â””â”€â”€ OFFLINE â†’ Routes to Local GGUF Model (private, always available)
```

---

## ğŸ› ï¸ Technology Stack

### Frontend
- **React** + Vite
- **TailwindCSS** for styling
- **Lucide Icons**
- Auto network detection

### Backend
- **FastAPI** (Python)
- **llama-cpp-python** for local inference
- **Cerebras Cloud SDK** for online mode
- Conversation memory management

### MCP Gateway
- Custom **Model Context Protocol** gateway
- Automatic network detection
- Intelligent routing between providers
- Health monitoring

### Infrastructure
- **Docker** + Docker Compose
- Microservices architecture
- Container health checks

---

## ğŸ“¦ What's Included

- âœ… **3 Dockerfiles** (Frontend, Backend, Gateway)
- âœ… **docker-compose.yml** - Orchestrates all services
- âœ… **MCP Gateway** - Custom network-aware router
- âœ… **Local Model** - Llama 2 7B (4-bit quantized)
- âœ… **Auto-detection** - No manual mode switching
- âœ… **Health checks** - Automatic service recovery
- âœ… **Complete documentation**

---

## ğŸ¯ Use Cases

Perfect for:
- ğŸŒ **Remote/Rural Areas** - Limited internet connectivity
- âœˆï¸ **Travel** - Unreliable mobile connections
- ğŸ¥ **Healthcare** - Privacy-sensitive environments
- ğŸ“ **Education** - Schools with poor connectivity
- ğŸš¢ **Maritime/Aviation** - Isolated environments
- ğŸ’¼ **Enterprise** - Air-gapped networks

---

## ğŸ“Š System Requirements

### Minimum
- Docker Desktop installed
- 8 GB RAM
- 15 GB free disk space
- Windows 10/11, macOS, or Linux

### Recommended
- 16 GB RAM
- 20 GB free disk space (SSD preferred)
- 4+ CPU cores

---

## ğŸ§ª Testing Network Switching

1. Start the app with internet connection
2. Send a message â†’ Uses **Cerebras** (fast response)
3. Disable WiFi/Internet
4. Send another message â†’ Automatically switches to **Local Model**
5. Re-enable internet â†’ Switches back to **Cerebras**
6. Previous offline messages auto-enhance âœ¨

**No manual toggle needed!**

---

## ğŸ“ Commands

```bash
# Start application
docker-compose up

# Start in background
docker-compose up -d

# Stop application
docker-compose down

# View logs
docker-compose logs -f

# Rebuild after changes
docker-compose up --build
```

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ‘¥ Team Cyber_Samurais

Built for **WeMakeDevs FutureStack GenAI Hackathon 2025**

---

## ğŸ™ Acknowledgments

- **Cerebras** for the lightning-fast AI API
- **Meta** for the Llama 2 model
- **Docker** for containerization technology
- **FastAPI** & **React** communities

---

**Made with â¤ï¸ to bridge the digital divide**
